{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "from functools import partial\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "import chex\n",
    "from chex import PRNGKey\n",
    "\n",
    "from pgx import State\n",
    "\n",
    "from type_aliases import Observation, Reward, Done, Action\n",
    "import connect_four_env as env\n",
    "import mcts_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pvp(rng: PRNGKey, policy1, policy2, batch_size: int):\n",
    "    def single_move(prev: tuple[State, Observation], rng: PRNGKey) -> tuple[tuple[State, Observation], Reward]:\n",
    "        state, observation = prev\n",
    "        rng0, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "        action0 = policy1(rng0, state)\n",
    "        action1 = policy2(rng1, state)\n",
    "        action = jnp.where(state.current_player == 0, action0, action1)\n",
    "    \n",
    "        new_state, new_observation, new_reward, new_done = jax.vmap(env.step_autoreset)(state, action, jax.random.split(rng2, batch_size))\n",
    "        return (new_state, new_observation), (-new_reward * (state.current_player * 2 - 1), new_done)\n",
    "\n",
    "    rng, subkey = jax.random.split(rng)\n",
    "    state, observation = jax.vmap(env.reset)(jax.random.split(subkey, batch_size))\n",
    "    \n",
    "    first = state, observation\n",
    "    _, out = jax.lax.scan(single_move, first, jax.random.split(rng, env.max_steps))\n",
    "    rewards, done = out\n",
    "    chex.assert_shape(rewards, [env.max_steps, batch_size])\n",
    "    chex.assert_shape(done, [env.max_steps, batch_size])\n",
    "\n",
    "    num_episodes = done.sum()\n",
    "    wins = ((rewards[:, :] > 0) & done).sum() / num_episodes\n",
    "    draws = ((rewards[:, :] == 0) & done).sum() / num_episodes\n",
    "    losses = ((rewards[:, :] < 0) & done).sum() / num_episodes\n",
    "    return wins, draws, losses\n",
    "\n",
    "\n",
    "def random_policy(rng: PRNGKey, state: State) -> chex.Array:\n",
    "    logits = jnp.zeros(env.num_actions)\n",
    "    action_mask = state.legal_action_mask\n",
    "    logits_masked = jnp.where(action_mask, logits, -1e9)\n",
    "    return jax.random.categorical(rng, logits_masked)\n",
    "\n",
    "\n",
    "def make_mcts_policy(num_simulations: int):\n",
    "    def mcts_policy(rng: PRNGKey, state: State) -> chex.Array:\n",
    "        out = mcts_agent.batched_compute_policy(rng, state, num_simulations)\n",
    "        logits = out.action_weights\n",
    "        action_mask = state.legal_action_mask\n",
    "        logits_masked = jnp.where(action_mask, logits, -1e9)\n",
    "        return logits_masked.argmax(axis=-1)\n",
    "    return mcts_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.51399493, dtype=float32),\n",
       " Array(0.00127226, dtype=float32),\n",
       " Array(0.48473284, dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pvp(jax.random.key(0), random_policy, random_policy, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.82758623, dtype=float32),\n",
       " Array(0., dtype=float32),\n",
       " Array(0.1724138, dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pvp(jax.random.key(0), make_mcts_policy(16), random_policy, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.9066667, dtype=float32),\n",
       " Array(0.01333333, dtype=float32),\n",
       " Array(0.08, dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_pvp(jax.random.key(0), make_mcts_policy(64), make_mcts_policy(16), 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
